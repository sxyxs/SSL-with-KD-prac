{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e748a375-3418-4fb5-bcb3-05902ffe87b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fin\n",
      "0      5\n",
      "1      0\n",
      "2      4\n",
      "3      1\n",
      "4      9\n",
      "      ..\n",
      "96     7\n",
      "97     8\n",
      "98     3\n",
      "99     1\n",
      "100    5\n",
      "Name: label, Length: 101, dtype: int64\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_46064/3435187207.py:36: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.258853840835856\n",
      "1\n",
      "0.2341905903052774\n",
      "2\n",
      "0.19223125987078687\n",
      "3\n",
      "0.17743339433044444\n",
      "4\n",
      "0.17792255989024505\n",
      "5\n",
      "0.17798231314166912\n",
      "6\n",
      "0.17799513328354113\n",
      "7\n",
      "0.17799859969816134\n",
      "8\n",
      "0.1779995892228162\n",
      "9\n",
      "0.17799987833498795\n",
      "10\n",
      "0.17799996379073776\n",
      "11\n",
      "0.17799998919748372\n",
      "12\n",
      "0.17799999677328807\n",
      "13\n",
      "0.17799999903558317\n",
      "14\n",
      "0.17799999971165817\n",
      "15\n",
      "0.17799999991377718\n",
      "16\n",
      "0.17799999997421456\n",
      "17\n",
      "0.17799999999228833\n",
      "18\n",
      "0.17799999999769364\n",
      "19\n",
      "0.1779999999993102\n",
      "[2.30227933e-01 8.58330165e-02 1.47346630e-01 1.68257340e-02\n",
      " 1.22204231e-01 1.14225564e-01 9.97249081e-01 1.04908024e-02\n",
      " 5.68132124e-04 1.74712352e-02] 5\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#read data\n",
    "# test_set = np.loadtxt(\"mnist_test.csv\",skiprows=1,delimiter=\",\")\n",
    "# dataset = np.loadtxt(\"mnist_train.csv\",skiprows=1,delimiter=\",\")\n",
    "\n",
    "#\n",
    "dataset = pd.read_csv(\"./mnist_train.csv\", delimiter=',', nrows = 101)\n",
    "# print(dataset.loc[0]) #Name: 0, Length: 785, dtype: int64\n",
    "# print(dataset.loc[0][0]) #5\n",
    "#input:dataset.loc[i][1:]\n",
    "#truth:dataset.loc[i][0]\n",
    "\n",
    "#can change to optimize\n",
    "numLayer = 1\n",
    "numNeu = 5\n",
    "learn_rate = 0.1\n",
    "epochs = 20\n",
    "numWeight = 784*numNeu + numNeu*10 # only working when numLayer = 1\n",
    "numOutputs = 10\n",
    "numBias = numNeu + numOutputs\n",
    "\n",
    "input_train = dataset[dataset.columns[1:]]\n",
    "output_gt_val = dataset[dataset.columns[0]]\n",
    "\n",
    "output_gt_set = np.zeros([100,10])\n",
    "for i in range(100):\n",
    "    for j in range(10):\n",
    "        if j == output_gt_val[i]: \n",
    "            output_gt_set[i][j] = 1 \n",
    "#print(output_gt_set)\n",
    "def sigmoid(x):\n",
    "  # Sigmoid activation function: f(x) = 1 / (1 + e^(-x))\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def deriv_sigmoid(x):\n",
    "  # Derivative of sigmoid: f'(x) = f(x) * (1 - f(x))\n",
    "  fx = sigmoid(x)\n",
    "  return fx * (1 - fx)\n",
    "\n",
    "def mse_loss(y_true, y_pred):\n",
    "  # y_true and y_pred are numpy arrays of the same length.\n",
    "  return ((y_true - y_pred) ** 2).mean()\n",
    "\n",
    "class NeuralNet():\n",
    "    def __init__(self):\n",
    "        self.weight = {}\n",
    "        self.bias = {}\n",
    "        self.loss = {}\n",
    "        self.output = np.zeros([100,10])\n",
    "        self.output_sum = np.zeros([100,10])\n",
    "        self.layer1 = np.zeros(numNeu)\n",
    "        self.sum_layer1 = np.zeros(numNeu)\n",
    "        self.dyp_dweight = np.zeros(10*numNeu)\n",
    "        self.dhl_dweight = np.zeros(784*numNeu)\n",
    "        self.dhl_dbias = np.zeros(numNeu+numOutputs)\n",
    "        self.dyp_dbias = np.zeros(numOutputs)\n",
    "        self.yp_hl = np.zeros(numNeu)\n",
    "        self.deriv_ypred_each = np.zeros(10)\n",
    "        \n",
    "    \n",
    "    def init_weights_and_bias(self):\n",
    "        for i in range(numWeight):\n",
    "            self.weight[i] = np.random.normal()\n",
    "\n",
    "        for i in range(numBias):\n",
    "            self.bias[i] = np.random.normal()\n",
    "    \n",
    "    def test(self, input):\n",
    "        output = np.zeros(10)\n",
    "        index_weight = 0\n",
    "        for j in range(784):\n",
    "            for k in range(numNeu):\n",
    "                self.sum_layer1[k] += input[j]*self.weight[index_weight] + self.bias[k]\n",
    "                index_weight+=1\n",
    "    \n",
    "        # sigmoid layer\n",
    "        for ii in range(numNeu):\n",
    "            self.layer1[ii] = sigmoid(self.sum_layer1[ii])\n",
    "            \n",
    "        #hidden layer1 to output\n",
    "        for ii in range(10):\n",
    "            for j in range(5):\n",
    "                output[ii] += self.layer1[j] * self.weight[index_weight] + self.bias[ii+5]\n",
    "            output[ii] = sigmoid(output[ii])\n",
    "        return output\n",
    "\n",
    "    def forward(self,input,output_gt_set):\n",
    "        \n",
    "        for epoch in range(epochs):\n",
    "\n",
    "            print(epoch)\n",
    "            # input to hidden layer1\n",
    "            for i in range(100): #100 data len\n",
    "                i_input = input_train.loc[i]\n",
    "                index_weight = 0\n",
    "                for j in range(784):\n",
    "                    for k in range(numNeu):\n",
    "                        self.sum_layer1[k] += i_input[j]*self.weight[index_weight] + self.bias[k]\n",
    "                        index_weight+=1\n",
    "            \n",
    "                # sigmoid layer\n",
    "                for ii in range(numNeu):\n",
    "                    self.layer1[ii] = sigmoid(self.sum_layer1[ii])\n",
    "                    \n",
    "                #hidden layer1 to output\n",
    "                for ii in range(10):\n",
    "                    for j in range(5):\n",
    "                        self.output_sum[i][ii] += self.layer1[j] * self.weight[index_weight] + self.bias[ii+5]\n",
    "                    self.output[i][ii] = sigmoid(self.output_sum[i][ii])\n",
    "                \n",
    "                # dl/dw = dl/dyp * dyp/dh (hidden layer) * dh/dw\n",
    "                # dl/db = dl/dyp * dyp/dh (hidden layer) * dh/db\n",
    "                #mse loss\n",
    "                \n",
    "                diff = (self.output[i] - output_gt_set[i])\n",
    "                dL_dypred = 2 * np.sum(diff)\n",
    "                for j in range(10):\n",
    "                    self.deriv_ypred_each[j] = self.output[i][j] - output_gt_set[i][j]\n",
    "\n",
    "                #所有weight的index+1是 % 5 == 1 ==>  h0\n",
    "                #               % 5 == 2 ==>  h1\n",
    "                #               % 5 == 3 ==>  h2\n",
    "                #               % 5 == 4 ==>  h3\n",
    "                #               % 5 == 0 ==>  h4\n",
    "                #          一共784轮\n",
    "                \n",
    "                # deriv weight input-hidden\n",
    "                weight_index_bp = 0\n",
    "                for j in range(784):\n",
    "                    for k in range(numNeu):\n",
    "                        if (k+1) % 5 == 1:\n",
    "                            self.dhl_dweight[weight_index_bp] = i_input[j] * deriv_sigmoid(self.sum_layer1[0])\n",
    "                        elif (k+1) % 5 == 2:\n",
    "                            self.dhl_dweight[weight_index_bp] = i_input[j] * deriv_sigmoid(self.sum_layer1[1])\n",
    "                        elif (k+1) % 5 == 3:\n",
    "                            self.dhl_dweight[weight_index_bp] = i_input[j] * deriv_sigmoid(self.sum_layer1[2])\n",
    "                        elif (k+1) % 5 == 4:\n",
    "                            self.dhl_dweight[weight_index_bp] = i_input[j] * deriv_sigmoid(self.sum_layer1[3])\n",
    "                        elif (k+1) % 5 == 0:\n",
    "                            self.dhl_dweight[weight_index_bp] = i_input[j] * deriv_sigmoid(self.sum_layer1[4])\n",
    "                        weight_index_bp += 1\n",
    "\n",
    "                # deriv weight hidden-output\n",
    "                weight_index_bp = 0\n",
    "                for j in range(10):\n",
    "                    for k in range(numNeu):\n",
    "                        self.dyp_dweight[weight_index_bp] = deriv_sigmoid(self.output[i][j]) * self.layer1[k]\n",
    "                        weight_index_bp += 1\n",
    "                \n",
    "                # deriv hidden-output yp_hl \n",
    "                # numNeu = 5\n",
    "                weight_index_bp = numNeu * 784\n",
    "                for k in range(10):\n",
    "                    for j in range(numNeu):\n",
    "                        self.yp_hl[j] = self.weight[weight_index_bp] * deriv_sigmoid(self.output_sum[i][k])\n",
    "                        weight_index_bp += 1\n",
    "\n",
    "\n",
    "                \n",
    "                # deriv bias\n",
    "                for j in range(numNeu):\n",
    "                    self.dhl_dbias[j] = deriv_sigmoid(self.sum_layer1[j])\n",
    "                \n",
    "                for j in range(numOutputs):\n",
    "                    self.dhl_dbias[j+numNeu] = deriv_sigmoid(self.output_sum[i][j])\n",
    "\n",
    "\n",
    "\n",
    "                # update each weight\n",
    "                # self.w1 -= learn_rate * d_L_d_ypred * d_ypred_d_h1 * d_h1_d_w1\n",
    "                    # before hl\n",
    "                #w0: in0->hl0\n",
    "                #w1: in0->hl1\n",
    "                #w2: in0->hl2\n",
    "                ind = 0\n",
    "                for j in range(784):\n",
    "                    for k in range(numNeu):\n",
    "                        self.weight[ind] -= learn_rate * dL_dypred *self.dhl_dweight[ind] * self.yp_hl[k]\n",
    "                        ind += 1\n",
    "\n",
    "                    # after hl\n",
    "                    #self.w5 -= learn_rate * d_L_d_y1 * d_ypred_d_w5\n",
    "                ind = 0\n",
    "                for j in range(numNeu):\n",
    "                    for k in range(10):\n",
    "                        self.weight[ind+784*numNeu] -= learn_rate * self.deriv_ypred_each[k] * self.dyp_dweight[ind]\n",
    "                        ind += 1\n",
    "\n",
    "                # update each bias\n",
    "                    #bias in hl self.b2 -= learn_rate * d_L_d_ypred * d_ypred_d_h2 * d_h2_d_b2\n",
    "                for j in range(numNeu):\n",
    "                    self.bias[j] -= learn_rate * dL_dypred * self.yp_hl[j] * self.dhl_dbias[j]\n",
    "                #bias in yp self.b3 -= learn_rate * d_L_d_y1 * d_ypred_d_b3\n",
    "                for j in range(numOutputs):\n",
    "                    self.bias[j+numNeu] -= learn_rate * self.deriv_ypred_each[j] * self.dhl_dbias[j+numNeu]\n",
    "\n",
    "                # def mse_loss(y_true, y_pred):\n",
    "            print(mse_loss(output_gt_set,self.output))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                    \n",
    "\n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "aa = NeuralNet()\n",
    "aa.init_weights_and_bias()\n",
    "print(\"fin\")\n",
    "print(output_gt_val)\n",
    "\n",
    "aa.forward(dataset.loc[0:][1:],output_gt_set)\n",
    "\n",
    "print(aa.test(input_train.values.tolist()[0]), output_gt_val[0])\n",
    "\n",
    "# 1. forward\n",
    "# 2. loss calcualte\n",
    "# 3. bp\n",
    "# 4. repeat\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b0dd8170",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5ef0f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e87ce287-817b-477f-8178-2c03115a9046",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47083978 0.76042087 0.00079617 0.42050592 0.04771674 0.67999765\n",
      " 0.44681841 0.61897953 0.67143945 0.4582522 ] 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:36: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "print(aa.test(input_train.values.tolist()[0]), output_gt_val[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "061c3b65-a61a-4f16-b7d2-b5a780bc33c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.47083978 0.76042087 0.00079617 0.42050592 0.04771674 0.67999765\n",
      " 0.44681841 0.61897953 0.67143945 0.4582522 ] 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:36: RuntimeWarning: overflow encountered in exp\n"
     ]
    }
   ],
   "source": [
    "print(aa.test(input_train.values.tolist()[1]), output_gt_val[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5efeaf8-f4ce-4c87-9b14-1746a0044623",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/ipykernel_launcher.py:36: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "for i in range(100):\n",
    "    #print(input_train.values.tolist()[i])\n",
    "    print(np.argmax(aa.test(input_train.values.tolist()[i])))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f774e4ec-91c3-4d79-80ae-3cdc2d73a100",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([20, 1, 28, 28]) torch.Size([20])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fda5d14d760>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "## 配置其他超参数，如batch_size, num_workers, learning rate, 以及总的epochs\n",
    "batch_size = 20\n",
    "num_workers = 4   # 对于Windows用户，这里应设置为0，否则会出现多线程错误\n",
    "lr = 1e-4\n",
    "epochs = 20\n",
    "\n",
    "image_size = 28\n",
    "data_transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),  \n",
    "     # 这一步取决于后续的数据读取方式，如果使用内置数据集读取方式则不需要\n",
    "    transforms.Resize(image_size),\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "class MDataset(Dataset):\n",
    "    def __init__(self, df, transform=None):\n",
    "        self.df = df\n",
    "        self.transform = transform\n",
    "        self.images = df.iloc[:,1:].values.astype(np.uint8)\n",
    "        self.labels = df.iloc[:, 0].values\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        image = self.images[idx].reshape(28,28,1)\n",
    "        label = int(self.labels[idx])\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        else:\n",
    "            image = torch.tensor(image/255., dtype=torch.float)\n",
    "        label = torch.tensor(label, dtype=torch.long)\n",
    "        return image, label\n",
    "\n",
    "train_df = pd.read_csv(\"./dataset/part_of_mnist_train.csv\")\n",
    "test_df = pd.read_csv(\"./dataset/mnist_test.csv\")\n",
    "\n",
    "train_data = MDataset(train_df, data_transform)\n",
    "test_data = MDataset(test_df, data_transform)\n",
    "\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=num_workers, drop_last=True)\n",
    "test_loader = DataLoader(test_data, batch_size=batch_size, shuffle=False, num_workers=num_workers)\n",
    "\n",
    "\n",
    "image, label = next(iter(train_loader))\n",
    "print(image.shape, label.shape)\n",
    "plt.imshow(image[5][0], cmap=\"gray\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "15af823b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "dataset = pd.read_csv(\"./dataset/part_of_mnist_train.csv\", delimiter=',', nrows = 20000)\n",
    "\n",
    "input_train = dataset[dataset.columns[1:]]\n",
    "output_gt_val = dataset[dataset.columns[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aa512e08",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7    117\n",
       "1    116\n",
       "4    105\n",
       "9    100\n",
       "2     99\n",
       "0     97\n",
       "6     94\n",
       "3     93\n",
       "5     92\n",
       "8     87\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(output_gt_val[0:1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "227d3ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
